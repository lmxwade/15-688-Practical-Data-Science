{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Library\n",
    "\n",
    "**THIS IS ONLY FOR 15-688 STUDENTS**\n",
    "\n",
    "In this problem, you're going to write a (very minimal) graph library, which uses both the adjacency dictionary and the sparse adjacency matrix representation of a graph.  Using these two representations, you'll implement two of the more well-known large-scale graph processing algorithms: Djisktra's algorithm for finding single-source shortest paths in the graph, and the PageRank algorithm for determining the importance of nodes in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `wikipedia_small` graph\n",
    "\n",
    "The graph we'll be focusing on for most of this assignment is a directed graph that represents the page links in the English language Wikipedia.  Specifically, we took the (pre-processed) Wikipedia dump from here: http://haselgrove.id.au/wikipedia.htm , which were taken from a 2008 version of Wikipedia, and we then selected only subselected only those nodes that had at least _500 incoming links_.  This resulted in a graph with about 24,000 nodes and 6,000,000 edges.\n",
    "\n",
    "There are two files included with this notebook that are relevant here:\n",
    "\n",
    "- `wikipedia_small.graph.gz`\n",
    "- `wikipedia_small.nodes.gz`\n",
    "    \n",
    "The `.graph.gz` file contains a (gzipped) list of integers, two per each line.  If the line \"`i j`\" appears in the file, this indicates a directed edge from node `i` to node `j`.  The `.nodes.gz` file then contains a (gzipped) list of each node the the graph, where the link number indicates the node index.  This is how we can relate the node numbers in the `.graph.gz` file to actual pages on Wikipedia.\n",
    "\n",
    "Don't decompress the `.gz` files - we do that while reading them. This is common practice when dealing with large amounts of text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup using `networkx`\n",
    "\n",
    "Bundled with this handout is `hw2_graph_library_warmup.ipynb`, which introduces you to the `networkx` library. We recommend (but not require) that you do that first. You are not allowed to use the `networkx` library in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your own Graph class\n",
    "\n",
    "In the main portion of this assignment, you'll create your own Graph class that mimics some of the functionality of networkx (and which will indeed be much faster than networkx when it comes to algorithms like PageRank). We'll provide you with some scaffolding and support code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import heapdict\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "from testing.testing import test\n",
    "\n",
    "SIMPLE_TEST_GRAPH = [(\"A\",\"B\"), (\"B\",\"C\"), (\"A\",\"D\"), (\"D\", \"E\"), (\"E\", \"B\")]\n",
    "\n",
    "# Utility function to keep a copy of the list in memory:\n",
    "global _files_cache\n",
    "_files_cache = None\n",
    "def test_graph():\n",
    "    global _files_cache\n",
    "    if _files_cache is None:\n",
    "        _files_cache = read_files()\n",
    "    # Return a generator so users can't mess with the cached file.\n",
    "    # Avoids the overhead of copying the list:\n",
    "    return (n for n in _files_cache)\n",
    "\n",
    "# Utility function to read the edges:\n",
    "def read_files(basename=\"wikipedia_small\"):\n",
    "    with gzip.open(f\"{basename}.nodes.gz\", 'rt',encoding='UTF-8') as f:\n",
    "        nodes = [a.strip() for a in f]\n",
    "    with gzip.open(f\"{basename}.graph.gz\", 'rt') as f:\n",
    "        links = []\n",
    "        for row in f:\n",
    "            i, j = tuple(row.strip().split())\n",
    "            links.append((nodes[int(i)], nodes[int(j)]))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template\n",
    "\n",
    "Here is the template for your Graph class.\n",
    "\n",
    "Note that `self.edges` should be represented as an \"adjacency dictionary\", so that for every node `i` in the graph `self.edges[i]` is a dictionary of nodes that `i` is directly connected to. The value of the inner dictionary should be `1` for every edge that exists and `0` otherwise. (The value of this entry doesn't matter, so we could technically use a dictionary of sets, but we use a dictionary of dictionaries to keep things a little bit more uniform and to allow for potential extensions e.g. to weighted graphs.)\n",
    "\n",
    "Note that all vertices must exist in the dictionary. If a vertex has no outgoing edges, then it should still have an entry pointing to an empty dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, initial_edges=None):\n",
    "        \"\"\" Initialize with an empty dictionary-of-sets. \"\"\"\n",
    "        self.edges = defaultdict(lambda: defaultdict(int))\n",
    "        if initial_edges is not None:\n",
    "            self.add_edges(initial_edges)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Number of edges in the graph \"\"\"\n",
    "        return sum(len(v) for v in self.edges.values())\n",
    "\n",
    "    def add_edges(self, edges_list):\n",
    "        \"\"\" Add a list of edges to the network. Use 1 to indiciate the presence of an edge. \n",
    "\n",
    "        Args:\n",
    "            edges_list: list of (a, b) tuples, where a -> b is an edge to add\n",
    "        \"\"\"\n",
    "#         print(edges_list)\n",
    "        for source, dest in edges_list:\n",
    "            self.edges[source][dest] = 1\n",
    "            if (dest not in self.edges.keys()):\n",
    "                self.edges[dest] = defaultdict(int)\n",
    "#         print(self.edges)\n",
    "\n",
    "    # We will implement these functions later:\n",
    "    def shortest_path(self, source):\n",
    "        return shortest_path_impl(self.edges, source)\n",
    "    \n",
    "    def adjacency_matrix(self):\n",
    "        return adjacency_matrix_impl(self.edges)\n",
    "    \n",
    "    def pagerank(self, d=0.85, iters=100):\n",
    "        return pagerank(self.adjacency_matrix(), d, iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Implement `add_edges()` call\n",
    "\n",
    "To begin, implement the function `add_edges()` in the code above. It must modify the `self.edges` variable to add all edges passed as tuples in `edges_list`.\n",
    "\n",
    "We will test your `add_edges()` implementation on this graph:\n",
    "\n",
    "    A -> B -> C\n",
    "    |    ^\n",
    "    v    |\n",
    "    D -> E\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING add_edges_impl: PASSED 6/6\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def add_edges_impl_test(add_edges_impl):\n",
    "    G = add_edges_impl(SIMPLE_TEST_GRAPH)\n",
    "    \n",
    "    # If this test fails, you need to make sure that nodes with no outgoing edges are present in G.edges:\n",
    "    test.true(\"C\" in G.edges)\n",
    "    # If this test fails, you need to make sure that al values are `int(1)`.\n",
    "    test.true(all(all(vv == 1 for vv in v.values()) for v in G.edges.values()))\n",
    "\n",
    "    test.equal(set(G.edges.keys()), set(\"ABCDE\"))\n",
    "    test.equal(set(G.edges[\"A\"].keys()), set(\"BD\"))\n",
    "    \n",
    "    # Load the test graph. This may take a few seconds:\n",
    "    G = add_edges_impl(test_graph())\n",
    "    test.equal(len(G.edges), 24166)\n",
    "    test.equal(len(G.edges[\"Carnegie_Mellon_University\"]), 162)\n",
    "\n",
    "@test\n",
    "def add_edges_impl(edges):\n",
    "    return Graph(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Djisktra's algorithm\n",
    "\n",
    "Next, implement Djisktra's single-source shortest path algorithm (with the simple case where the distance along any edge is assumed to be one).  You can refer to the [Wikipedia page on Djikstra's algorithm](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm) for reference. The basic idea of the algorithm is to keep a priority queue of nodes ordered by distance from a source node.  At each step, we continually pop off the smallest element `i` in the queue, and update the distance of all successor nodes to have a distance of `1 + distance[i]`.\n",
    "\n",
    "For the priority queue, you should use a [`heapdict`](https://github.com/DanielStutzbach/heapdict), which is a form of priority queue that allows you to change the priority of an element.\n",
    "\n",
    "When called with source node `A`, the function should return a dictionary where the keys are all the nodes in the graph. For each key `B`:\n",
    "\n",
    "- if `B` is reachable from `A` then the value must be the tuple `(distance, prev_node)`, where:\n",
    "  - `distance` is the minimum number of hops from `A` to `B`, and\n",
    "  - `prev_node` is the node immediately before `B` along one such shortest path\n",
    "- if `B` is not reachable from `A`, then the value must be `None`\n",
    "- if `B == A`, then the value should be `(0, None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING shortest_path_impl: PASSED 9/9\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from heapdict import heapdict\n",
    "\n",
    "def shortest_path_impl_test(shortest_path_impl):\n",
    "    G = Graph(SIMPLE_TEST_GRAPH)\n",
    "    sp = shortest_path_impl(G.edges, \"A\")\n",
    "    # Check that you correctly handle `B==A`:\n",
    "    test.equal(sp['A'], (0, None))\n",
    "#     Simple test:\n",
    "    test.equal(sp, {'A': (0, None), 'B': (1, 'A'), 'C': (2, 'B'), 'D': (1, 'A'), 'E': (2, 'D')})\n",
    "    \n",
    "    # Check that you correctly handle unreachable nodes:\n",
    "    test.equal(shortest_path_impl(G.edges, \"B\"), {'A': None, 'B': (0, None), 'C': (1, 'B'), 'D': None, 'E': None})\n",
    "\n",
    "    # Load the test graph. This should take <15s:\n",
    "    G = add_edges_impl(test_graph())\n",
    "    sp = shortest_path_impl(G.edges, \"Carnegie_Mellon_University\")\n",
    "    test.equal(sp[\"Singapore\"], (1, \"Carnegie_Mellon_University\"))\n",
    "    test.equal(sp[\"Data\"][0], 2)\n",
    "    test.equal(sp[\"List_of_Salticidae_species\"][0], 5)\n",
    "    # Unreachable nodes\n",
    "    test.equal(sp['Village_Development_Committee_(Nepal)'], None)\n",
    "    test.equal(sp['Voice_acting_in_Japan'], None)\n",
    "    \n",
    "    # The maximum distance is 5. We determined this in the warmup:\n",
    "    test.equal(max(*(d for d,_ in filter(lambda x: x, sp.values()))), 5)\n",
    "\n",
    "\n",
    "@test\n",
    "def shortest_path_impl(edges, source):\n",
    "    \"\"\" Compute the single-source shorting path.\n",
    "\n",
    "    This function uses Djikstra's algorithm to compute the distance from \n",
    "    source to all other nodes in the network.\n",
    "\n",
    "    Args:\n",
    "        source: node index for the source\n",
    "\n",
    "    Returns: Dict[str, Optional[Tuple[int, str]]]\n",
    "        dictionary of node: (distance, prev_node) values for each reachable node in the graph, where \n",
    "              distance denotes the shortest distance from of node from source, and\n",
    "              prev_node is the previous node on the shortest path from source to node.\n",
    "            if node is unreachable, the value should be None\n",
    "    \"\"\"\n",
    "    \n",
    "    dist = heapdict()\n",
    "    prev = dict()\n",
    "    result = dict()\n",
    "    for n in edges.keys():\n",
    "#         print(n)\n",
    "        dist[n] = sys.maxsize\n",
    "        prev[n] = None\n",
    "    \n",
    "    dist[source] = 0\n",
    "    \n",
    "    while(len(dist) != 0):\n",
    "        node, distance = dist.popitem()\n",
    "        for neighbor in edges[node]:\n",
    "            if neighbor in dist.keys():\n",
    "                alt = distance + 1\n",
    "                if (alt < dist[neighbor]):\n",
    "                    dist[neighbor] = alt\n",
    "                    prev[neighbor] = node\n",
    "        if (prev[node] == None and distance != 0):\n",
    "            result[node] = None\n",
    "        else:\n",
    "            result[node] = (distance, prev[node])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Adjacency matrix representation\n",
    "\n",
    "Implement the adjacency matrix method of the Graph class.  This returns a matrix representing the adjacency of the graph (in scipy COO sparse format), as well as a list of nodes that indicate how the indices in this graph relate to the nodes in the network.\n",
    "\n",
    "In order to complete this question in a manner that works on the Wikipedia, you must implement this function natively as a sparse matrix (i.e., you cannot construct a dense matrix and then convert that to a sparse matrix, but need to directly use the `sp.coo_matrix()` constructor).  The Wikipedia graph is is 24K x 24K nodes, which (assuming 8 bytes per entry, would take up 4GB of memory.  While it's not impossible to do things this way at this scale (it quickly becomes infeasible for graphs that are even slightly larger), it's a very bad idea, and just allocating this much memory will take too long.\n",
    "\n",
    "**Note the order of the axes of the output matrix.** This is important for calculating the PageRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING adjacency_matrix_impl: PASSED 8/8\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def adjacency_matrix_impl_test(adjacency_matrix_impl):\n",
    "    def check(graph):\n",
    "        G = Graph(graph)\n",
    "        adj, nodes = adjacency_matrix_impl(G.edges)\n",
    "        # Check output type:\n",
    "        test.true(isinstance(adj, sp.coo_matrix))\n",
    "        test.equal(str(adj.dtype), \"uint8\")\n",
    "        # Make sure there are the correct number of entries:\n",
    "        test.equal(adj.sum(), len(G))\n",
    "        # Make sure that every entry is represented:\n",
    "        lookup = { node : i for i, node in enumerate(nodes) }\n",
    "        adj_lil = adj.tolil() # Convert to linked-list sparse matrix for lookups:\n",
    "        test.true(all(adj_lil[lookup[j], lookup[i]]==1 for i, j in graph))\n",
    "\n",
    "    check(SIMPLE_TEST_GRAPH)\n",
    "    check(test_graph())\n",
    "\n",
    "@test\n",
    "def adjacency_matrix_impl(edges):\n",
    "    \"\"\" Compute an adjacency matrix form of the graph.\n",
    "\n",
    "    Returns: tuple(A, nodes)\n",
    "        A : sp.coo_matrix[np.uint8] -- a sparse adjacency matrix with underlying `dtype=np.uint8` that represents the graph (i.e., `A[j,i] == 1` iff there is an edge i->j)\n",
    "           NOTE: be sure you have this ordering correct!\n",
    "        nodes : List[str] -- a list of nodes indicating the key corresponding to each index of the `A` matrix\n",
    "    \"\"\"\n",
    "    List = [k for k in edges.keys()]\n",
    "    Dict = {List[index]:index for index in range(0,len(List))}\n",
    "    row = []\n",
    "    col = []\n",
    "\n",
    "    for source in edges.keys(): \n",
    "        for dest in edges[source].keys():\n",
    "            row.append(Dict[dest])\n",
    "            col.append(Dict[source])\n",
    "\n",
    "    data = [1 for _ in range(len(row))]\n",
    "    A = coo_matrix((data,(row,col)), dtype=np.uint8, shape = (len(List),len(List)))\n",
    "    \n",
    "    return (A, List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your code works on the Wikipedia graph.  In our implementation, it takes 7 seconds to run all tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: PageRank algorithm\n",
    "\n",
    "Finally, implement the PageRank algorithm using the adjacency matrix representation. You should use the approach described in the [\"Power Method\" section on the Wikipedia entry](https://en.wikipedia.org/wiki/PageRank#Power_Method), which we also discussed in class.\n",
    "\n",
    "This involves forming some initial uniform probability vector $x$, and repeatly multiplying it by the matrices:\n",
    "\\begin{equation}\n",
    "x \\gets \\left(d P + \\left(\\frac{1-d}{n}\\right) E \\right)x\n",
    "\\end{equation}\n",
    "where $P$ is a transition matrix, $E$ is the matrix of all ones, and $d$ is the damping factor. You get $P$ by normalizing $A$ so that all columns have sum 1.\n",
    "\n",
    "Recall that from the definition of PageRank, when we reach a \"sink\" node (a node with no outgoing edges), we randomly hop to any other node in the network, so that columns of $P$ that have no outgoing edges are set to the uniform distribution.  To be efficient, you'll also want to avoid explicitly forming the $E$ matrix, and should instead use the fact that $E = 1*1^T$ where $1$ denotes a vector of all ones.  Use the fact that we can reorder matrix multiplication if associative (i.e., the fact the $A(BC)$ = $(AB)C$) to make this operation as fast as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your function should return a dictionary of nodes and their corresponding page rank.  For example, in our graph above, we have the following results:\n",
    "```\n",
    "C: 0.324\n",
    "B: 0.281\n",
    "E: 0.188\n",
    "D: 0.121\n",
    "A: 0.085\n",
    "```\n",
    "As is intuitive, nodes B and C have higher page rank, as they are pointed to by more of the other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING pagerank_impl: PASSED 15/15\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pagerank_impl_test(pagerank_impl):\n",
    "    G = Graph(SIMPLE_TEST_GRAPH)\n",
    "    pagerank = pagerank_impl(G.adjacency_matrix())    \n",
    "    test.true(abs(pagerank['A']-0.08510862387068166) < 1e-7)\n",
    "    test.true(abs(pagerank['B']-0.28124676686965944) < 1e-7)\n",
    "    test.true(abs(pagerank['C']-0.3241683757098922) < 1e-7)\n",
    "    test.true(abs(pagerank['D']-0.12127978901572137) < 1e-7)\n",
    "    test.true(abs(pagerank['E']-0.18819644453404483) < 1e-7)\n",
    "\n",
    "    G = Graph(test_graph())\n",
    "    pagerank = pagerank_impl(G.adjacency_matrix())\n",
    "\n",
    "    test.equal(len(pagerank), 24166)\n",
    "\n",
    "    # Numerical check\n",
    "    test.true(abs(pagerank['United_States'] - 0.00275188705264) < 1e-5)\n",
    "    test.true(abs(pagerank['2008'] - 0.00217342514773) < 1e-5)\n",
    "    test.true(abs(pagerank['Canada'] - 0.00109896195215) < 1e-5)\n",
    "    test.true(abs(pagerank['World_War_II'] - 0.00104913079624) < 1e-5)\n",
    "    test.true(abs(pagerank['List_of_African_films'] - 0.00100713870383) < 1e-5)\n",
    "    test.true(abs(pagerank['Europe'] - 0.000937690025073) < 1e-5)\n",
    "    test.true(abs(pagerank['English_language'] - 0.000908144359626) < 1e-5)\n",
    "    test.true(abs(pagerank['Geographic_coordinate_system'] - 0.000891711151403) < 1e-5)\n",
    "    test.true(abs(pagerank['Latin'] - 0.000888662228804) < 1e-5)\n",
    "\n",
    "@test\n",
    "def pagerank_impl(adjacency_matrix, d=0.85, iters=100):\n",
    "    \"\"\" Compute the PageRank score for each node in the network.\n",
    "\n",
    "    Compute PageRank scores using the power method.\n",
    "\n",
    "    Args:\n",
    "        adjacency_matrix: Tuple[A, nodes] -- output from Graph.adjacency_matrix()\n",
    "    \n",
    "    Keyword Args:\n",
    "        d: 1 - random restart factor\n",
    "        iters: maximum number of iterations of power method\n",
    "\n",
    "    Returns: dict ranks\n",
    "        ranks: a dictionary of node:importance score, for each node in the\n",
    "               network (larger score means higher rank)\n",
    "\n",
    "    \"\"\"\n",
    "    A, nodes = adjacency_matrix\n",
    "    n,_ = A.shape\n",
    "    sums = A.sum(0).T          \n",
    "    B = A.tocsr()\n",
    "\n",
    "    r = np.ones((n,1))/n\n",
    "    for _ in range(0,iters):\n",
    "        with np.errstate(divide='ignore'):\n",
    "            r1 = B.dot(r*d/sums)\n",
    "        r1 = r1 + (1 - r1.sum())/n\n",
    "        r = r1\n",
    "#     print(r)\n",
    "    Dict = {}\n",
    "    for i in range(0, len(r)):\n",
    "        Dict[nodes[i]] = float(r[i])\n",
    "#     print(Dict)\n",
    "    return Dict\n",
    "    \n",
    "# Xindi Lan explained to me the basic idea of solving Q4: PageRank algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your implementation works on the full Wikipedia graph (in our implementation, it takes 11 seconds to run, most of which is taken up by generating the adjacency matrix).  The top PageRank entires we get from our implementation are:\n",
    "\n",
    "```\n",
    "United_States     2.75e-3\n",
    "2007              2.44e-3\n",
    "2008              2.17e-3\n",
    "Wikimedia_Commons 1.72e-3\n",
    "United_Kingdom    1.59e-3\n",
    "2006              1.54e-3\n",
    "France            1.44e-3\n",
    "Wiktionary        1.26e-3\n",
    "Canada            1.09e-3\n",
    "World_War_II      1.04e-3\n",
    "2005              1.04e-3\n",
    "List_of_Africa... 1.00e-3\n",
    "Germany           0.95e-3\n",
    "Europe            0.93e-3\n",
    "English_language  0.90e-3\n",
    "Geographic_coo... 0.89e-3\n",
    "Latin             0.88e-3\n",
    "Australia         0.87e-3\n",
    "India             0.78e-3\n",
    "Japan             0.78e-3\n",
    "```\n",
    "\n",
    "countries and years! A seemingly reasonable list of pages we may expect to be important."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
